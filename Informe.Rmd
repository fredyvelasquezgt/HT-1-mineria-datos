---
title: "Informe Hoja de trabajo 2"
author: "Pablo Escobar, Fredy Velasquez, Angel Higueros"
date: "18/2/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


```


# Hoja de Trabajo: 2, Clustering

### 1. Haga el preprocesamiento del dataset, explique qué variables no aportan información a la generación de grupos y por qué. Describa con qué variables calculará los grupos.
```{r wid}

library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(ggrepel)

#Preprocesamiento 
datos<-read.csv("movies.csv")

#Normalizar datos

datos<-datos[complete.cases(read.csv("movies.csv")),]
popularidad<-datos[,'popularity']
presupuesto<-datos[,'budget']
ingresos<-datos[,'revenue']
duracion<-datos[,'runtime']
conteoVotos<-datos[,'voteCount']
cle<-data.frame(popularidad,presupuesto,ingresos,duracion,conteoVotos)
clusteringVar<-scale(cle)

```
Las variables que no se usaron para el agrupamiento fueron las variables categóricas porque no son las adecuadas para el análisis. Sin embargo se puede analizar pero usando o tomando como base las numéricas para establecer relaciones.<br/>

Se usaron las siguientes variables:<br/> popularity: Que es el índice de popularidad de la película calculado semanalmente.<br/> budget: El presupuesto para la película.<br/> revenue: El ingreso de la película.<br/> runtime: La duración de la película.<br/> voteCount: El número de votos en la plataforma para la película.<br/> 

### 2. Analice la tendencia al agrupamiento usando el estadístico de Hopkings y la VAT (Visual Assessment of cluster Tendency) Discuta sus resultados e impresiones. 

```{r} 

hopkins(clusteringVar)

#Matriz de distancia
datos_dist<- dist(clusteringVar)

```
Como se puede ver, el valor del estadístico de Hopkins tiene un valor muy lejano a 0.5, por lo que no son datos aleatorios, lo que nos podría facilitar un agrupamiento.  

Ahora, usando un método gráfico, si nos basamos en la gráfica siguiente: 

```{r}
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
fviz_dist(datos_dist, show_labels = F)

```

Como se puede observar en la VAT, existen patrones, algunos definidos, por lo que se ratifica que el dato que arroja el estadístico de Hopkins, es correcto.




### 3. Determine cuál es el número de grupos a formar más adecuado para los datos que está trabajando. 
Haga una gráfica de codo y explique la razón de la elección de la cantidad de clústeres con la que 
trabajará.


``` {r}
#Metodo de codo
wss=0
for (i in 1:10) 
  wss[i] <- sum(kmeans(cle, centers=i)$withinss)

plot(1:10, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares")


```
Basándonos en el método de codo, el número perfecto para trabajar es de 3, ya que, siguiendo la teoría del método, el punto de inflexión es igual a 3.  



```{r}

#Metodo de silueta
fviz_nbclust(clusteringVar, kmeans, method = "silhouette") +
  labs(subtitle = "Silhouette method")

```
Al igual que el método del codo, el número de clusters ideal es de 3, pero para este método, se tomó en cuenta el número de agrupaciones que tenga una silueta más elevada. 


#### 5. Determine la calidad del agrupamiento hecho por cada algoritmo con el método de la silueta. Discuta los resultados. 

{r}
df <- data.frame(algoritmo=c("K-mean", "Jerarquico", "Gaussiano"),
                silueta=c(Kmean, Jerarquico, Gaussiano))
head(df)
library(ggplot2)
p<-ggplot(data=df, aes(x=algoritmo, y=silueta, fill=algoritmo)) +
  geom_bar(stat="identity")
p


Como se observa en la gráfica, la que obtuvo mejores resultados fue Cluster jerárquico, con un resultado de `r Jerarquico`, podríamos decir que el Agrupamiento Jerárquico fue el mejor, ya que este cuenta con la ventaja de que cualquier medida de distancia puede ser usada, dicho sea de paso, nosotros utilizamos la matriz de distancia, por eso es que hace que se vuelva tan eficiente en comparación a los otros métodos.

#### 6. Interprete los grupos basado en el conocimiento que tiene de los datos. Recuerde investigar las medidas de tendencia central de las variables continuas y las tablas de frecuencia de las variables categóricas pertenecientes a cada grupo. Identifique hallazgos interesantes debido a las agrupaciones y describa para qué le podría servir.

{r}
table(datos$genres,datos$grupo)


Con la información de las tablas anteriores, se puede determinar con mayor facilidad la coleccion de datos, ya que tenemos el resumen de la cantidad de veces que se repite un elemento, esto es muy importante sobre todo cuando hablamos de variables categoricas, entonces a base del clustering de las variables numericas, nos facilita la organizacion y obtencion de informacion de las variables categoricas
